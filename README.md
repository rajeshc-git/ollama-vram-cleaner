# ğŸ§ ğŸ’¨ Ollama Memory Unloader

âš¡ **Free Up System Memory (RAM) and GPU VRAM** Instantly by Unloading Ollama Models âš¡

ğŸš€ Whether you're running low on resources or just want to keep your system snappy, this lightweight tool lets you **unload inactive Ollama models** to save memory and VRAM. Perfect for developers, ML enthusiasts, and anyone juggling multiple models!

---

## ğŸ§© Features

âœ… One-click unloading of models  
âœ… Frees up both **System RAM** and **GPU VRAM**  
âœ… CLI & Script-friendly  
âœ… Lightweight â€“ no bloat  
âœ… Works seamlessly with Ollama-installed models  

---

## ğŸ”§ How It Works

This tool interacts with the Ollama runtime and ensures that any idle or loaded models are **safely unloaded** from both system memory and GPU, giving you back your resources for other tasks.

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/rajeshc-git/ollama-vram-cleaner.git
cd ollama-vram-cleaner
# Optional: create venv
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
ğŸš€ Usage
ğŸ–¥ï¸ Command Line
bash
Copy
Edit
python unload.py
Youâ€™ll see a list of loaded models and confirmation once theyâ€™re successfully unloaded.

ğŸ”’ Safe to Use
âœ… Doesn't delete or corrupt models
âœ… Simply unloads from memory, just like closing a tab
âœ… Re-load anytime using your regular Ollama commands

ğŸŒ Cross-Platform
ğŸªŸ Windows

ğŸ macOS

ğŸ§ Linux

ğŸ›  Requirements
Python 3.7+

Ollama properly installed and configured

ğŸ™Œ Contributions Welcome
Found a bug? Have a feature request? PRs and issues are always welcome!

ğŸ§™â€â™‚ï¸ Maintainer
Made with â¤ï¸ by Rajesh

ğŸ§¼ Keep It Clean. Keep It Fast.
â€œUnload the unused. Unleash the speed.â€ âš¡
